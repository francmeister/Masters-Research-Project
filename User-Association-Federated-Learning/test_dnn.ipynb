{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from DNN import DNN\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from numpy import interp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "         super(DNN, self).__init__()\n",
    "         self.fc1 = nn.Linear(input_dim, 100)\n",
    "         self.relu = nn.ReLU()\n",
    "         self.fc2 = nn.Linear(100, 100)\n",
    "         self.fc3 = nn.Linear(100, output_dim)\n",
    "         #self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_TRAINING_MEMORY():\n",
    "\n",
    "  def __init__(self, max_size=40):\n",
    "    self.storage = []\n",
    "    self.max_size = max_size\n",
    "    self.ptr = 0\n",
    "\n",
    "  def add(self, transition):\n",
    "    if len(self.storage) == self.max_size:\n",
    "      self.storage[int(self.ptr)] = transition\n",
    "      self.ptr = (self.ptr + 1) % self.max_size\n",
    "    else:\n",
    "      self.storage.append(transition)\n",
    "\n",
    "  def sample(self, batch_size):\n",
    "    ind = np.random.randint(0, len(self.storage), size=batch_size)\n",
    "    X_inputs, y_outputs, sample_rewards = [], [], []\n",
    "    for i in ind:\n",
    "      X_input, y_output, sample_reward = self.storage[i]\n",
    "      X_inputs.append(np.array(X_input, copy=False))\n",
    "      y_outputs.append(np.array(y_output, copy=False))\n",
    "      sample_rewards.append(np.array(sample_reward, copy=False))\n",
    "    return np.array(X_inputs), np.array(y_outputs), np.array(sample_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 1\n",
    "\n",
    "distance_to_AP_1 = 0.000000005\n",
    "distance_to_AP_2 = 0.001\n",
    "distance_to_AP_3 = 2000\n",
    "\n",
    "num_input_features = 2\n",
    "num_access_points = 3\n",
    "num_users = 1\n",
    "\n",
    "dnn = DNN(num_input_features,num_users)\n",
    "training_memory = DNN_TRAINING_MEMORY()\n",
    "\n",
    "# Generate random samples for initial training\n",
    "user_ids = []\n",
    "distances = []\n",
    "channel_gains = []\n",
    "input_features = []\n",
    "rewards = []\n",
    "user_associations = []\n",
    "buffer_memory = []\n",
    "channel_rate_inputs = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,40):\n",
    "    user_id = 1\n",
    "    distance = random.random()\n",
    "    channel_gain = random.random()\n",
    "    reward = random.random()\n",
    "    user_association = random.randint(1,3)\n",
    "    channel_rate = random.random()\n",
    "\n",
    "    user_ids.append(user_id)\n",
    "    distances.append(distance)\n",
    "    channel_gains.append(channel_gain)\n",
    "    rewards.append(reward)\n",
    "    channel_rate_inputs.append(channel_rate)\n",
    "    user_associations.append(user_association)\n",
    "\n",
    "for x in range(0,40):\n",
    "    input_features.append([user_ids[x], channel_rate_inputs[x]])\n",
    "\n",
    "input_features = np.array(input_features)\n",
    "user_associations = np.array(user_associations)\n",
    "rewards = np.array(rewards)\n",
    "\n",
    "#print(rewards)\n",
    "\n",
    "for x in range(0,40):\n",
    "    training_memory.add((input_features[x], user_associations[x], rewards[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def preprocessing(distance, channel_gain):\n",
    "def preprocessing(channel_rate):\n",
    "    features = []\n",
    "    distance_normalized = interp(distance,[0,2000],[0,500])\n",
    "    channel_gain_normalized = interp(channel_gain,[0,10],[0,1])\n",
    "    #channel_rate_normalized = interp(channel_gain,[0,100],[0,1])\n",
    "    channel_rate_normalized = channel_rate\n",
    "\n",
    "    features.append(1)\n",
    "    #features.append(distance_normalized)\n",
    "    #features.append(channel_gain_normalized)\n",
    "    features.append(channel_rate_normalized)\n",
    "\n",
    "    features = np.array(features)\n",
    "    return features\n",
    "\n",
    "def calculate_channel_rate(distance, channel_gain):\n",
    "    channel_rate_numerator = 400*math.pow(distance,-1)*channel_gain\n",
    "    channel_rate_denominator = 1\n",
    "    RB_bandwidth = 12000\n",
    "    channel_rate = RB_bandwidth*math.log2(1+(channel_rate_numerator/channel_rate_denominator))\n",
    "\n",
    "    return channel_rate/1000\n",
    "\n",
    "def prediction_future_association(distance, channel_gain):\n",
    "    current_channel_rate = calculate_channel_rate(distance,channel_gain)\n",
    "    preprocessed_inputs = preprocessing(current_channel_rate)\n",
    "    preprocessed_inputs_tensor = torch.Tensor(preprocessed_inputs).to(device)\n",
    "    association_prediction = dnn(preprocessed_inputs_tensor)\n",
    "    association_prediction = association_prediction.detach().numpy()\n",
    "    #print(association_prediction[0])\n",
    "    association_prediction = round(association_prediction[0])\n",
    "\n",
    "    if association_prediction > 3:\n",
    "        association_prediction = 3\n",
    "    elif association_prediction < 1:\n",
    "        association_prediction = 1\n",
    "\n",
    "    buffer_memory.append((preprocessed_inputs,association_prediction,0))\n",
    "\n",
    "    return association_prediction\n",
    "\n",
    "def populate_buffer_memory_sample_with_reward(current_association_reward):\n",
    "    rewards_in_memory = []\n",
    "    if len(buffer_memory) > 1:\n",
    "        new_sample = (buffer_memory[0][0],buffer_memory[0][1],current_association_reward)\n",
    "        buffer_memory[0] = new_sample\n",
    "        dnn_memory_rewards = []\n",
    "        for sample in training_memory.storage:\n",
    "            dnn_memory_rewards.append(sample[2])\n",
    "        max_index = dnn_memory_rewards.index(max(dnn_memory_rewards))\n",
    "\n",
    "        if current_association_reward >= dnn_memory_rewards[max_index]:\n",
    "            training_memory.add(buffer_memory[0])\n",
    "            #print('SBS: ', self.SBS_label, 'Appended')\n",
    "\n",
    "        buffer_memory.pop(0)\n",
    "    for sample in training_memory.storage:\n",
    "        rewards_in_memory.append(sample[2])\n",
    "    \n",
    "    average_reward_in_memory = sum(rewards_in_memory)/len(rewards_in_memory) + random.random()\n",
    "    return average_reward_in_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_association = 3\n",
    "current_distance = distance_to_AP_3\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dnn.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(dnn.parameters(), lr=0.001)\n",
    "num_training_epochs = 100\n",
    "training_loss = []\n",
    "average_rewards_in_memory = []\n",
    "channel_rates = []\n",
    "training_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for x in range(0,400):\n",
    "\n",
    "    x_train, y_train, sample_rewards = training_memory.sample(20)\n",
    "    #print('x_train: ', x_train)\n",
    "    y_train = y_train.reshape(20,1)\n",
    "    x_train_tensor = torch.Tensor(x_train).to(device)\n",
    "    y_train_tensor = torch.Tensor(y_train).to(device)\n",
    "\n",
    "    if x_train_tensor.dtype != dnn.fc1.weight.dtype:\n",
    "        x_train_tensor = x_train_tensor.to(dnn.fc1.weight.dtype)\n",
    "        y_train_tensor = y_train_tensor.to(dnn.fc1.weight.dtype)\n",
    "\n",
    "    for epoch in range(num_training_epochs):\n",
    "            y_pred_tensor = dnn(x_train_tensor)\n",
    "            loss = criterion(y_pred_tensor, y_train_tensor)\n",
    "            training_loss.append(loss.detach().numpy())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    if current_association == 1:\n",
    "        current_distance = distance_to_AP_1\n",
    "    elif current_association == 2:\n",
    "        current_distance = distance_to_AP_2\n",
    "    elif current_association == 3:\n",
    "        current_distance = distance_to_AP_3\n",
    "\n",
    "\n",
    "    current_channel_gain = np.random.exponential(1)\n",
    "    #current_distance = 2000\n",
    "    #print(current_distance)\n",
    "    current_channel_rate = calculate_channel_rate(current_distance,current_channel_gain)\n",
    "    channel_rates.append(current_channel_rate)\n",
    "    #print(current_channel_rate)\n",
    "\n",
    "    future_association = prediction_future_association(current_distance, current_channel_gain)\n",
    "    #future_association = prediction_future_association(current_channel_rate)\n",
    "    #print(future_association)\n",
    "    current_association = future_association\n",
    "\n",
    "    average_reward_in_memory = populate_buffer_memory_sample_with_reward(current_channel_rate)\n",
    "    average_rewards_in_memory.append(average_reward_in_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_1 = \"channel_rates\"\n",
    "file_name_2 = \"average_rewards_in_memory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./results\"):\n",
    "  os.makedirs(\"./results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./results/%s\" % (file_name_1), channel_rates)\n",
    "np.save(\"./results/%s\" % (file_name_2), average_rewards_in_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps_average_rewards_in_memory = []\n",
    "timesteps_channel_rates = []\n",
    "timesteps_training_loss = []\n",
    "\n",
    "x = 0\n",
    "for gb in average_rewards_in_memory:\n",
    "    timesteps_average_rewards_in_memory.append(x)\n",
    "    x+=1\n",
    "\n",
    "x = 0\n",
    "for gb in channel_rates:\n",
    "    timesteps_channel_rates.append(x)\n",
    "    x+=1\n",
    "\n",
    "x = 0\n",
    "for gb in training_loss:\n",
    "    timesteps_training_loss.append(x)\n",
    "    x+=1\n",
    "\n",
    "\n",
    "#print(average_rewards_in_memory)\n",
    "#plt.plot(timesteps_average_rewards_in_memory, average_rewards_in_memory, color =\"blue\")\n",
    "#plt.plot(timesteps_channel_rates, channel_rates, color =\"blue\")\n",
    "#plt.plot(timesteps_training_loss, training_loss, color =\"blue\")\n",
    "\n",
    "#plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
